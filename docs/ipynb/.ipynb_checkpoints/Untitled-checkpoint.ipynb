{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script demonstrates the utility of MyVariant.info and MyGene.info to annotate variants and prioritize candidate genes in patients with rare Mendelian diseases. This specific study uses data obtained from the database of phenotype and genotype (dbGaP) study...FASTQ files generated by Ng et al for the Miller syndrome study. FASTQ files were processed according to the Broad Institute’s best practices. Individual samples were aligned to the hg19 reference genome using BWA-MEM 0.7.10. Variants were called using GATK 3.3-0 HaplotypeCaller and quality scores were recalibrated using GATK VariantRecalibrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(myvariant)\n",
    "library(mygene)\n",
    "library(VariantAnnotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setwd(\"~/sulab/myvariant/vcf/\")\n",
    "vcf.files <- paste(getwd(), list.files(getwd()), sep=\"/\")\n",
    "source(\"~/sulab/repos/myvariant.info/docs/ipynb/mendelian.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function reads in each output VCF file using the VariantAnnotation package available from Bioconductor. Install with biocLite(\"VariantAnnotation\"). formatHgvs is a myvariant.R function that reads the genomic location and variant information from the VCF to create HGVS IDs which serve as a primary key for each variant. The function getVariants makes the queries to MyVariant.info to retrieve annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found header lines for 3 ‘fixed’ fields: ALT, QUAL, FILTER \n",
      "found header lines for 24 ‘info’ fields: AC, AF, AN, BaseQRankSum, ClippingRankSum, DB, DP, DS, END, FS, HaplotypeScore, InbreedingCoeff, MLEAC, MLEAF, MQ, MQ0, MQRankSum, NEGATIVE_TRAIN_SITE, POSITIVE_TRAIN_SITE, QD, ReadPosRankSum, SOR, VQSLOD, culprit \n",
      "found header lines for 5 ‘geno’ fields: GT, AD, DP, GQ, PL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying chunk 1 of 40\n",
      "Querying chunk 2 of 40\n",
      "Querying chunk 3 of 40\n",
      "Querying chunk 4 of 40\n",
      "Querying chunk 5 of 40\n",
      "Querying chunk 6 of 40\n",
      "Querying chunk 7 of 40\n",
      "Querying chunk 8 of 40\n",
      "Querying chunk 9 of 40\n",
      "Querying chunk 10 of 40\n",
      "Querying chunk 11 of 40\n",
      "Querying chunk 12 of 40\n",
      "Querying chunk 13 of 40\n",
      "Querying chunk 14 of 40\n",
      "Querying chunk 15 of 40\n",
      "Querying chunk 16 of 40\n",
      "Querying chunk 17 of 40\n",
      "Querying chunk 18 of 40\n",
      "Querying chunk 19 of 40\n",
      "Querying chunk 20 of 40\n",
      "Querying chunk 21 of 40\n",
      "Querying chunk 22 of 40\n",
      "Querying chunk 23 of 40\n",
      "Querying chunk 24 of 40\n",
      "Querying chunk 25 of 40\n",
      "Querying chunk 26 of 40\n",
      "Querying chunk 27 of 40\n",
      "Querying chunk 28 of 40\n",
      "Querying chunk 29 of 40\n",
      "Querying chunk 30 of 40\n",
      "Querying chunk 31 of 40\n",
      "Querying chunk 32 of 40\n",
      "Querying chunk 33 of 40\n",
      "Querying chunk 34 of 40\n",
      "Querying chunk 35 of 40\n",
      "Querying chunk 36 of 40\n",
      "Querying chunk 37 of 40\n",
      "Querying chunk 38 of 40\n",
      "Querying chunk 39 of 40\n",
      "Querying chunk 40 of 40\n",
      "Concatenating data, please be patient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found header lines for 3 ‘fixed’ fields: ALT, QUAL, FILTER \n",
      "found header lines for 24 ‘info’ fields: AC, AF, AN, BaseQRankSum, ClippingRankSum, DB, DP, DS, END, FS, HaplotypeScore, InbreedingCoeff, MLEAC, MLEAF, MQ, MQ0, MQRankSum, NEGATIVE_TRAIN_SITE, POSITIVE_TRAIN_SITE, QD, ReadPosRankSum, SOR, VQSLOD, culprit \n",
      "found header lines for 5 ‘geno’ fields: GT, AD, DP, GQ, PL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying chunk 1 of 39\n",
      "Querying chunk 2 of 39\n",
      "Querying chunk 3 of 39\n",
      "Querying chunk 4 of 39\n",
      "Querying chunk 5 of 39\n",
      "Querying chunk 6 of 39\n",
      "Querying chunk 7 of 39\n",
      "Querying chunk 8 of 39\n",
      "Querying chunk 9 of 39\n",
      "Querying chunk 10 of 39\n",
      "Querying chunk 11 of 39\n",
      "Querying chunk 12 of 39\n",
      "Querying chunk 13 of 39\n",
      "Querying chunk 14 of 39\n",
      "Querying chunk 15 of 39\n",
      "Querying chunk 16 of 39\n",
      "Querying chunk 17 of 39\n",
      "Querying chunk 18 of 39\n",
      "Querying chunk 19 of 39\n",
      "Querying chunk 20 of 39\n",
      "Querying chunk 21 of 39\n",
      "Querying chunk 22 of 39\n",
      "Querying chunk 23 of 39\n",
      "Querying chunk 24 of 39\n",
      "Querying chunk 25 of 39\n",
      "Querying chunk 26 of 39\n",
      "Querying chunk 27 of 39\n",
      "Querying chunk 28 of 39\n",
      "Querying chunk 29 of 39\n",
      "Querying chunk 30 of 39\n",
      "Querying chunk 31 of 39\n",
      "Querying chunk 32 of 39\n",
      "Querying chunk 33 of 39\n",
      "Querying chunk 34 of 39\n",
      "Querying chunk 35 of 39\n",
      "Querying chunk 36 of 39\n",
      "Querying chunk 37 of 39\n",
      "Querying chunk 38 of 39\n",
      "Querying chunk 39 of 39\n",
      "Concatenating data, please be patient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found header lines for 3 ‘fixed’ fields: ALT, QUAL, FILTER \n",
      "found header lines for 24 ‘info’ fields: AC, AF, AN, BaseQRankSum, ClippingRankSum, DB, DP, DS, END, FS, HaplotypeScore, InbreedingCoeff, MLEAC, MLEAF, MQ, MQ0, MQRankSum, NEGATIVE_TRAIN_SITE, POSITIVE_TRAIN_SITE, QD, ReadPosRankSum, SOR, VQSLOD, culprit \n",
      "found header lines for 5 ‘geno’ fields: GT, AD, DP, GQ, PL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying chunk 1 of 31\n",
      "Querying chunk 2 of 31\n",
      "Querying chunk 3 of 31\n",
      "Querying chunk 4 of 31\n",
      "Querying chunk 5 of 31\n",
      "Querying chunk 6 of 31\n",
      "Querying chunk 7 of 31\n",
      "Querying chunk 8 of 31\n",
      "Querying chunk 9 of 31\n",
      "Querying chunk 10 of 31\n",
      "Querying chunk 11 of 31\n",
      "Querying chunk 12 of 31\n",
      "Querying chunk 13 of 31\n",
      "Querying chunk 14 of 31\n",
      "Querying chunk 15 of 31\n",
      "Querying chunk 16 of 31\n",
      "Querying chunk 17 of 31\n",
      "Querying chunk 18 of 31\n",
      "Querying chunk 19 of 31\n",
      "Querying chunk 20 of 31\n",
      "Querying chunk 21 of 31\n",
      "Querying chunk 22 of 31\n",
      "Querying chunk 23 of 31\n",
      "Querying chunk 24 of 31\n",
      "Querying chunk 25 of 31\n",
      "Querying chunk 26 of 31\n",
      "Querying chunk 27 of 31\n",
      "Querying chunk 28 of 31\n",
      "Querying chunk 29 of 31\n",
      "Querying chunk 30 of 31\n",
      "Querying chunk 31 of 31\n",
      "Concatenating data, please be patient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found header lines for 3 ‘fixed’ fields: ALT, QUAL, FILTER \n",
      "found header lines for 24 ‘info’ fields: AC, AF, AN, BaseQRankSum, ClippingRankSum, DB, DP, DS, END, FS, HaplotypeScore, InbreedingCoeff, MLEAC, MLEAF, MQ, MQ0, MQRankSum, NEGATIVE_TRAIN_SITE, POSITIVE_TRAIN_SITE, QD, ReadPosRankSum, SOR, VQSLOD, culprit \n",
      "found header lines for 5 ‘geno’ fields: GT, AD, DP, GQ, PL \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying chunk 1 of 38\n",
      "Querying chunk 2 of 38\n",
      "Querying chunk 3 of 38\n",
      "Querying chunk 4 of 38\n",
      "Querying chunk 5 of 38\n",
      "Querying chunk 6 of 38\n",
      "Querying chunk 7 of 38\n",
      "Querying chunk 8 of 38\n",
      "Querying chunk 9 of 38\n",
      "Querying chunk 10 of 38\n",
      "Querying chunk 11 of 38\n",
      "Querying chunk 12 of 38\n",
      "Querying chunk 13 of 38\n",
      "Querying chunk 14 of 38\n",
      "Querying chunk 15 of 38\n",
      "Querying chunk 16 of 38\n",
      "Querying chunk 17 of 38\n",
      "Querying chunk 18 of 38\n",
      "Querying chunk 19 of 38\n",
      "Querying chunk 20 of 38\n",
      "Querying chunk 21 of 38\n",
      "Querying chunk 22 of 38\n",
      "Querying chunk 23 of 38\n",
      "Querying chunk 24 of 38\n",
      "Querying chunk 25 of 38\n",
      "Querying chunk 26 of 38\n",
      "Querying chunk 27 of 38\n",
      "Querying chunk 28 of 38\n",
      "Querying chunk 29 of 38\n",
      "Querying chunk 30 of 38\n",
      "Querying chunk 31 of 38\n",
      "Querying chunk 32 of 38\n",
      "Querying chunk 33 of 38\n",
      "Querying chunk 34 of 38\n",
      "Querying chunk 35 of 38\n",
      "Querying chunk 36 of 38\n",
      "Querying chunk 37 of 38\n",
      "Querying chunk 38 of 38\n",
      "Concatenating data, please be patient.\n"
     ]
    }
   ],
   "source": [
    "getVars <- function(vcf.file){\n",
    "  vcf <- readVcf(vcf.file, genome=\"hg19\")\n",
    "  vcf <- vcf[isSNV(vcf)]\n",
    "  vars <- rowRanges(vcf)\n",
    "  vars <- as(vars, \"DataFrame\")\n",
    "  vars$query <- formatHgvs(vcf, \"snp\")\n",
    "  annotations <- getVariants(vars$query)\n",
    "  annotations[c('DP', 'FS', 'QD')] <- info(vcf)[c('DP', 'FS', 'QD')]\n",
    "    ## replace 'NA' with 0\n",
    "  annotations <- replaceWith0(annotations)\n",
    "  annotations\n",
    "}\n",
    "\n",
    "vars <- lapply(vcf.files, getVars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'X_id'</li>\n",
       "\t<li>'query'</li>\n",
       "\t<li>'notfound'</li>\n",
       "\t<li>'dbsnp.allele_origin'</li>\n",
       "\t<li>'dbsnp.alleles'</li>\n",
       "\t<li>'dbsnp.alt'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'X_id'\n",
       "\\item 'query'\n",
       "\\item 'notfound'\n",
       "\\item 'dbsnp.allele_origin'\n",
       "\\item 'dbsnp.alleles'\n",
       "\\item 'dbsnp.alt'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'X_id'\n",
       "2. 'query'\n",
       "3. 'notfound'\n",
       "4. 'dbsnp.allele_origin'\n",
       "5. 'dbsnp.alleles'\n",
       "6. 'dbsnp.alt'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"X_id\"                \"query\"               \"notfound\"           \n",
       "[4] \"dbsnp.allele_origin\" \"dbsnp.alleles\"       \"dbsnp.alt\"          "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check annotaion fields\n",
    "head(names(vars[[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply the function to each of the VCF files and do our filtering based on coverage and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filterDf <- function(df){\n",
    "  df <- subset(df, DP > 15 & FS < 30 & QD > 2)\n",
    "  df <- subset(df, cadd.consequence %in% c(\"NON_SYNONYMOUS\", \"STOP_GAINED\", \"STOP_LOST\", \n",
    "                                           \"CANONICAL_SPLICE\", \"SPLICE_SITE\"))\n",
    "  df <- subset(df, exac.af < 0.01)\n",
    "  df <- subset(df, sapply(dbnsfp.1000gp1.af, function(i) i < 0.01 ))\n",
    "  df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered.annotations <- lapply(vars, filterDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then keep only genes that are mutated in each of the four patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene.counts <- data.frame(table(unlist(lapply(filtered.annotations, function(i) unique(i$dbnsfp.genename)))))\n",
    "top.genes <- subset(gene.counts, Freq == 4)\n",
    "top.genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can prioritize the 14 genes that contain variants in each of the patients according to CADD (deleteriousness) score. rankByCaddScore extracts the average CADD scores of the variants in each gene per patient and ranks in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranked <- rankByCaddScore(top.genes$Var1, filtered.annotations)\n",
    "ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ng et al concluded DHODH is responsible for Miller Syndrome as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
